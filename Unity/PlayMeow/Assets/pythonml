import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import tensorflow as tf
from tensorflow import keras
from xgboost import XGBRegressor
import joblib
import os

class LaserTurretMLPipeline:
    def __init__(self, data_path, output_dir="models"):
        """
        Initialize the ML pipeline for laser turret control
        
        Args:
            data_path (str): Path to the CSV data file from Unity recorder
            output_dir (str): Directory to save models and results
        """
        self.data_path = data_path
        self.output_dir = output_dir
        self.raw_data = None
        self.processed_data = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.models = {}
        self.results = {}
        
        # Create output directory if it doesn't exist
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
    def load_data(self):
        """Load data from CSV file generated by Unity recorder"""
        print(f"Loading data from {self.data_path}")
        self.raw_data = pd.read_csv(self.data_path)
        print(f"Loaded {len(self.raw_data)} records with columns: {self.raw_data.columns.tolist()}")
        return self.raw_data
    
    def explore_data(self):
        """Explore and visualize the data"""
        if self.raw_data is None:
            self.load_data()
            
        # Basic statistics
        print("\nData Summary:")
        print(self.raw_data.describe())
        
        # Check for missing values
        print("\nMissing Values:")
        print(self.raw_data.isnull().sum())
        
        # Visualize trajectories
        plt.figure(figsize=(15, 5))
        
        # Plot laser trajectory
        plt.subplot(1, 2, 1)
        plt.scatter(self.raw_data['LaserDot_X'], self.raw_data['LaserDot_Y'], 
                   c=self.raw_data['Time'], cmap='viridis', alpha=0.5)
        plt.colorbar(label='Time')
        plt.title('Laser Dot Trajectory (X-Y)')
        plt.xlabel('X Position')
        plt.ylabel('Y Position')
        
        # Plot tracker trajectory
        plt.subplot(1, 2, 2)
        plt.scatter(self.raw_data['Tracker_X'], self.raw_data['Tracker_Y'], 
                   c=self.raw_data['Time'], cmap='viridis', alpha=0.5)
        plt.colorbar(label='Time')
        plt.title('Cat Tracker Trajectory (X-Y)')
        plt.xlabel('X Position')
        plt.ylabel('Y Position')
        
        plt.tight_layout()
        plt.savefig(f"{self.output_dir}/trajectory_visualization.png")
        plt.close()
        
        # Calculate distance between laser and tracker over time
        self.raw_data['Distance'] = np.sqrt(
            (self.raw_data['LaserDot_X'] - self.raw_data['Tracker_X'])**2 +
            (self.raw_data['LaserDot_Y'] - self.raw_data['Tracker_Y'])**2 +
            (self.raw_data['LaserDot_Z'] - self.raw_data['Tracker_Z'])**2
        )
        
        # Plot distance over time
        plt.figure(figsize=(10, 5))
        plt.plot(self.raw_data['Time'], self.raw_data['Distance'])
        plt.title('Distance Between Laser Dot and Cat Tracker Over Time')
        plt.xlabel('Time (seconds)')
        plt.ylabel('Distance')
        plt.savefig(f"{self.output_dir}/distance_over_time.png")
        plt.close()
        
        return self.raw_data
    
    def preprocess_data(self, window_size=10, prediction_horizon=5):
        """
        Preprocess data to create time-series features
        
        Args:
            window_size (int): Number of past timesteps to use as features
            prediction_horizon (int): Number of future timesteps to predict
        """
        if self.raw_data is None:
            self.load_data()
            
        print(f"\nPreprocessing data with window_size={window_size}, prediction_horizon={prediction_horizon}")
        
        # Sort by time to ensure chronological order
        data = self.raw_data.sort_values('Time').reset_index(drop=True)
        
        # Calculate cat movement velocity and acceleration
        for coord in ['X', 'Y', 'Z']:
            # Velocity
            data[f'Tracker_Vel_{coord}'] = data[f'Tracker_{coord}'].diff() / data['Time'].diff()
            # Acceleration
            data[f'Tracker_Acc_{coord}'] = data[f'Tracker_Vel_{coord}'].diff() / data['Time'].diff()
            
        # Drop rows with NaN (first and second rows due to diff())
        data = data.dropna().reset_index(drop=True)
        
        # Create time-series input features (X) and target outputs (y)
        X_list = []
        y_list = []
        
        # Create windows of historical data
        for i in range(len(data) - window_size - prediction_horizon + 1):
            # Input features: cat position, velocity, acceleration history
            # and laser position history
            features = []
            
            # Get window of data
            window_data = data.iloc[i:i+window_size]
            
            # Extract cat position, velocity, acceleration
            for coord in ['X', 'Y', 'Z']:
                features.extend(window_data[f'Tracker_{coord}'].values)
                features.extend(window_data[f'Tracker_Vel_{coord}'].values)
                features.extend(window_data[f'Tracker_Acc_{coord}'].values)
                features.extend(window_data[f'LaserDot_{coord}'].values)
            
            # Target: future laser positions
            # Target window starts right after input window
            target_index = i + window_size
            target = []
            for j in range(prediction_horizon):
                if target_index + j < len(data):
                    # Predict future laser position
                    target.extend([
                        data.iloc[target_index + j][f'LaserDot_X'],
                        data.iloc[target_index + j][f'LaserDot_Y'],
                        data.iloc[target_index + j][f'LaserDot_Z']
                    ])
            
            # Only include samples where we have complete target data
            if len(target) == prediction_horizon * 3:
                X_list.append(features)
                y_list.append(target)
        
        # Convert to numpy arrays
        X = np.array(X_list)
        y = np.array(y_list)
        
        print(f"Created {len(X)} samples with input shape {X.shape} and output shape {y.shape}")
        
        # Scale the data
        X_scaler = StandardScaler()
        y_scaler = StandardScaler()
        
        X_scaled = X_scaler.fit_transform(X)
        y_scaled = y_scaler.fit_transform(y)
        
        # Save the scalers for later use
        joblib.dump(X_scaler, f"{self.output_dir}/X_scaler.pkl")
        joblib.dump(y_scaler, f"{self.output_dir}/y_scaler.pkl")
        
        # Split into train and test sets
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X_scaled, y_scaled, test_size=0.2, random_state=42
        )
        
        # Store processed data
        self.processed_data = {
            'X': X_scaled, 
            'y': y_scaled,
            'X_train': self.X_train,
            'X_test': self.X_test,
            'y_train': self.y_train,
            'y_test': self.y_test,
            'X_scaler': X_scaler,
            'y_scaler': y_scaler,
            'window_size': window_size,
            'prediction_horizon': prediction_horizon
        }
        
        print(f"Split data into {len(self.X_train)} training and {len(self.X_test)} testing samples")
        
        return self.processed_data
    
    def train_linear_model(self):
        """Train a linear regression model"""
        from sklearn.linear_model import LinearRegression
        
        if self.processed_data is None:
            self.preprocess_data()
            
        print("\nTraining Linear Regression model...")
        
        # Create and train model
        model = LinearRegression()
        model.fit(self.X_train, self.y_train)
        
        # Predict on test set
        y_pred = model.predict(self.X_test)
        
        # Evaluate model
        mse = mean_squared_error(self.y_test, y_pred)
        mae = mean_absolute_error(self.y_test, y_pred)
        r2 = r2_score(self.y_test, y_pred)
        
        print(f"Linear Regression Results - MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")
        
        # Save model
        joblib.dump(model, f"{self.output_dir}/linear_model.pkl")
        
        # Store model and results
        self.models['linear'] = model
        self.results['linear'] = {'mse': mse, 'mae': mae, 'r2': r2}
        
        return model, {'mse': mse, 'mae': mae, 'r2': r2}
    
    def train_xgboost_model(self):
        """Train an XGBoost model"""
        if self.processed_data is None:
            self.preprocess_data()
            
        print("\nTraining XGBoost model...")
        
        # Create and train model
        model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
        model.fit(self.X_train, self.y_train)
        
        # Predict on test set
        y_pred = model.predict(self.X_test)
        
        # Evaluate model
        mse = mean_squared_error(self.y_test, y_pred)
        mae = mean_absolute_error(self.y_test, y_pred)
        r2 = r2_score(self.y_test, y_pred)
        
        print(f"XGBoost Results - MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")
        
        # Save model
        joblib.dump(model, f"{self.output_dir}/xgboost_model.pkl")
        
        # Store model and results
        self.models['xgboost'] = model
        self.results['xgboost'] = {'mse': mse, 'mae': mae, 'r2': r2}
        
        return model, {'mse': mse, 'mae': mae, 'r2': r2}
    
    def train_lstm_model(self, reshape_for_lstm=True):
        """Train an LSTM model using PyTorch"""
        if self.processed_data is None:
            self.preprocess_data()
            
        print("\nTraining LSTM model...")
        
        # Define LSTM model
        class LSTMModel(nn.Module):
            def __init__(self, input_size, hidden_size, output_size, num_layers=1):
                super(LSTMModel, self).__init__()
                self.hidden_size = hidden_size
                self.num_layers = num_layers
                
                self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
                self.fc = nn.Linear(hidden_size, output_size)
                
            def forward(self, x):
                # Initialize hidden state and cell state
                h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
                c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
                
                # Forward propagate LSTM
                out, _ = self.lstm(x, (h0, c0))
                
                # Get the output from the last time step
                out = self.fc(out[:, -1, :])
                
                return out
        
        # Reshape data for LSTM if needed
        if reshape_for_lstm:
            # Get original window_size
            window_size = self.processed_data['window_size']
            
            # Calculate number of features per timestep
            features_per_timestep = self.X_train.shape[1] // window_size
            
            # Reshape training data: [batch_size, seq_len, features]
            X_train_reshaped = self.X_train.reshape(-1, window_size, features_per_timestep)
            X_test_reshaped = self.X_test.reshape(-1, window_size, features_per_timestep)
        else:
            # Use a sliding window approach directly on the preprocessed data
            # This requires reshaping the data differently
            features_per_timestep = self.X_train.shape[1]
            X_train_reshaped = self.X_train.reshape(-1, 1, features_per_timestep)
            X_test_reshaped = self.X_test.reshape(-1, 1, features_per_timestep)
        
        # Convert to PyTorch tensors
        X_train_tensor = torch.FloatTensor(X_train_reshaped)
        y_train_tensor = torch.FloatTensor(self.y_train)
        X_test_tensor = torch.FloatTensor(X_test_reshaped)
        y_test_tensor = torch.FloatTensor(self.y_test)
        
        # Create data loaders
        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)
        
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
        
        # Setup model
        input_size = features_per_timestep
        hidden_size = 64
        output_size = self.y_train.shape[1]  # Number of output features
        
        model = LSTMModel(input_size, hidden_size, output_size)
        
        # Loss and optimizer
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        # Training loop
        num_epochs = 50
        for epoch in range(num_epochs):
            model.train()
            running_loss = 0.0
            
            for inputs, targets in train_loader:
                # Forward pass
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                
                # Backward and optimize
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                running_loss += loss.item()
                
            epoch_loss = running_loss / len(train_loader)
            
            if (epoch + 1) % 10 == 0:
                print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')
        
        # Evaluate model
        model.eval()
        with torch.no_grad():
            y_pred_list = []
            
            for inputs, _ in test_loader:
                outputs = model(inputs)
                y_pred_list.append(outputs.numpy())
                
            y_pred = np.vstack(y_pred_list)
            
            # Calculate metrics
            mse = mean_squared_error(self.y_test, y_pred)
            mae = mean_absolute_error(self.y_test, y_pred)
            r2 = r2_score(self.y_test, y_pred)
            
            print(f"LSTM Results - MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")
        
        # Save model
        torch.save(model.state_dict(), f"{self.output_dir}/lstm_model.pth")
        
        # Store model and results
        self.models['lstm'] = model
        self.results['lstm'] = {'mse': mse, 'mae': mae, 'r2': r2}
        
        return model, {'mse': mse, 'mae': mae, 'r2': r2}
    
    def train_transformer_model(self):
        """Train a Transformer model using TensorFlow/Keras"""
        if self.processed_data is None:
            self.preprocess_data()
            
        print("\nTraining Transformer model...")
        
        # Reshape data for Transformer
        window_size = self.processed_data['window_size']
        features_per_timestep = self.X_train.shape[1] // window_size
        
        # Reshape to [batch_size, seq_len, features]
        X_train_reshaped = self.X_train.reshape(-1, window_size, features_per_timestep)
        X_test_reshaped = self.X_test.reshape(-1, window_size, features_per_timestep)
        
        # Build Transformer model
        def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):
            # Attention and normalization
            x = keras.layers.MultiHeadAttention(
                key_dim=head_size, num_heads=num_heads, dropout=dropout
            )(inputs, inputs)
            x = keras.layers.LayerNormalization(epsilon=1e-6)(x + inputs)
            
            # Feed forward network
            ff = keras.layers.Dense(ff_dim, activation="relu")(x)
            ff = keras.layers.Dense(inputs.shape[-1])(ff)
            ff = keras.layers.Dropout(dropout)(ff)
            
            # Add and normalize
            return keras.layers.LayerNormalization(epsilon=1e-6)(x + ff)
        
        # Build model
        inputs = keras.layers.Input(shape=(window_size, features_per_timestep))
        x = inputs
        
        # Positional encoding
        pos_encoding = keras.layers.Embedding(
            input_dim=window_size, 
            output_dim=features_per_timestep
        )(tf.range(start=0, limit=window_size, delta=1))
        
        x = x + pos_encoding
        
        # Transformer blocks
        for _ in range(2):
            x = transformer_encoder(x, head_size=32, num_heads=2, ff_dim=128, dropout=0.1)
        
        # Global average pooling and MLP head
        x = keras.layers.GlobalAveragePooling1D()(x)
        x = keras.layers.Dense(128, activation="relu")(x)
        x = keras.layers.Dropout(0.1)(x)
        outputs = keras.layers.Dense(self.y_train.shape[1])(x)
        
        model = keras.Model(inputs=inputs, outputs=outputs)
        
        # Compile model
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=1e-4),
            loss="mse"
        )
        
        # Train model
        history = model.fit(
            X_train_reshaped, self.y_train,
            epochs=50,
            batch_size=32,
            validation_split=0.1,
            callbacks=[
                keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)
            ],
            verbose=1
        )
        
        # Evaluate
        y_pred = model.predict(X_test_reshaped)
        
        # Calculate metrics
        mse = mean_squared_error(self.y_test, y_pred)
        mae = mean_absolute_error(self.y_test, y_pred)
        r2 = r2_score(self.y_test, y_pred)
        
        print(f"Transformer Results - MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")
        
        # Save model
        model.save(f"{self.output_dir}/transformer_model")
        
        # Plot training history
        plt.figure(figsize=(10, 6))
        plt.plot(history.history['loss'], label='Training Loss')
        plt.plot(history.history['val_loss'], label='Validation Loss')
        plt.xlabel('Epochs')
        plt.ylabel('Loss')
        plt.title('Transformer Model Training History')
        plt.legend()
        plt.savefig(f"{self.output_dir}/transformer_training_history.png")
        plt.close()
        
        # Store model and results
        self.models['transformer'] = model
        self.results['transformer'] = {'mse': mse, 'mae': mae, 'r2': r2}
        
        return model, {'mse': mse, 'mae': mae, 'r2': r2}

    def train_reinforcement_learning_model(self, n_episodes=1000):
        """
        Train a simple reinforcement learning model (DQN)
        This is simplified and would need to be adapted for real-world use
        """
        print("\nTraining Reinforcement Learning model...")
        
        # This would be a more complex implementation, but for now we're
        # showing a simplified approach for demonstration
        # In a real scenario, you'd want to use a proper RL framework like Stable Baselines
        
        class SimpleDQN(nn.Module):
            def __init__(self, state_dim, action_dim):
                super(SimpleDQN, self).__init__()
                self.fc1 = nn.Linear(state_dim, 64)
                self.fc2 = nn.Linear(64, 64)
                self.fc3 = nn.Linear(64, action_dim)
                
            def forward(self, x):
                x = torch.relu(self.fc1(x))
                x = torch.relu(self.fc2(x))
                return self.fc3(x)
        
        # We'd use the raw data differently for RL
        # Instead of predicting future positions, we'd define:
        # - States: cat position, velocity, current laser position
        # - Actions: discretized laser movement (e.g., move left, right, up, down)
        # - Rewards: based on cat engagement (could be distance or some behavior metric)
        
        print("Note: Full RL implementation would require integrating with Unity for online learning")
        print("      or creating a simulation environment based on the collected data.")
        
        # Return placeholder results to complete the pipeline
        placeholder_results = {'mse': float('nan'), 'mae': float('nan'), 'r2': float('nan')}
        self.results['rl'] = placeholder_results
        
        return None, placeholder_results
        
    def compare_models(self):
        """Compare the performance of all trained models"""
        if not self.results:
            print("No models have been trained yet.")
            return None
            
        print("\nModel Comparison:")
        comparison = pd.DataFrame({
            'Model': list(self.results.keys()),
            'MSE': [self.results[model]['mse'] for model in self.results],
            'MAE': [self.results[model]['mae'] for model in self.results],
            'R²': [self.results[model]['r2'] for model in self.results]
        })
        
        # Sort by MSE (lower is better)
        comparison = comparison.sort_values('MSE')
        
        print(comparison)
        
        # Create comparison chart
        plt.figure(figsize=(12, 6))
        
        # MSE comparison
        plt.subplot(1, 2, 1)
        sns.barplot(x='Model', y='MSE', data=comparison)
        plt.title('Mean Squared Error (lower is better)')
        plt.xticks(rotation=45)
        
        # R² comparison
        plt.subplot(1, 2, 2)
        sns.barplot(x='Model', y='R²', data=comparison)
        plt.title('R² Score (higher is better)')
        plt.xticks(rotation=45)
        
        plt.tight_layout()
        plt.savefig(f"{self.output_dir}/model_comparison.png")
        plt.close()
        
        return comparison
    
    def prepare_for_deployment(self, best_model_name):
        """
        Prepare the best model for deployment
        
        Args:
            best_model_name (str): Name of the best model to deploy
        """
        if best_model_name not in self.models:
            print(f"Model {best_model_name} not found.")
            return None
            
        print(f"\nPreparing {best_model_name} model for deployment...")
        
        # Export model and metadata for Unity integration
        model_info = {
            'model_name': best_model_name,
            'window_size': self.processed_data['window_size'],
            'prediction_horizon': self.processed_data['prediction_horizon'],
            'features_per_timestep': self.X_train.shape[1] // self.processed_data['window_size']
            if best_model_name in ['lstm', 'transformer'] else self.X_train.shape[1],
            'scalers_path': {
                'X_scaler': f"{self.output_dir}/X_scaler.pkl",
                'y_scaler': f"{self.output_dir}/y_scaler.pkl"
            },
            'model_path': f"{self.output_dir}/{best_model_name}_model"
            + ('.pth' if best_model_name == 'lstm' else '')
        }
        
        # Save model info
        import json
        with open(f"{self.output_dir}/model_info.json", 'w') as f:
            json.dump(model_info, f, indent=4)
            
        print(f"Model info saved to {self.output_dir}/model_info.json")
        
        # Generate sample C# code for Unity integration
        unity_integration_code = self.generate_unity_integration(best_model_name)
        
        with open(f"{self.output_dir}/UnityMLIntegration.cs", 'w') as f:
            f.write(unity_integration_code)
            
        print(f"Unity integration code saved to {self.output_dir}/UnityMLIntegration.cs")
        
        return model_info
    
    def generate_unity_integration(self, model_name):
        """Generate C# code for integrating the model with Unity"""
        # This would depend on the specific model type
        if model_name in ['linear', 'xgboost']:
            # These could be deployed using ONNX or TensorFlow.NET
            unity_code = """
using UnityEngine;
using System.Collections.Generic;
using System.IO;
using Microsoft.ML.OnnxRuntime; // Requires ONNX Runtime package

public class LaserTurretController : MonoBehaviour
{
    public GameObject laserDot;
    public GameObject tracker;
    
    public TextAsset modelAsset; // ONNX model file
    
    private InferenceSession session;
    private int windowSize;
    private int predictionHorizon;
    private List<float[]> historyBuffer = new List<float[]>();
    
    void Start()
    {
        // Load model
        byte[] modelData = modelAsset.bytes;
        session = new InferenceSession(modelData);
        
        // Set parameters from the model info
        windowSize = 10; // Replace with value from model_info.json
        predictionHorizon = 5; // Replace with value from model_info.json
    }
    
    void Update()
    {
        // Record current state
        Vector3 trackerPos = tracker.transform.position;
        Vector3 laserPos = laserDot.transform.position;
        
        // Calculate tracker velocity and acceleration
        // (This would need additional implementation to track over time)
        
        // Store in history buffer
        float[] currentState = new float[] {
            trackerPos.x, trackerPos.y, trackerPos.z,
            // Add velocity and acceleration
            laserPos.x, laserPos.y, laserPos.z
        };
        
        historyBuffer.Add(currentState);
        
        // Keep buffer at window size
        if (historyBuffer.Count > windowSize)
        {
            historyBuffer.RemoveAt(0);
        }
        
        // When we have enough history, predict next position
        if (historyBuffer.Count == windowSize)
        {
            Vector3 nextPosition = PredictNextPosition();
            
            // Move laser dot to predicted position
            // You might want to smooth this or implement a control strategy
            laserDot.transform.position = Vector3.Lerp(
                laserDot.transform.position, 
                nextPosition, 
                Time.deltaTime * 5f
            );
        }
    }
    
    Vector3 PredictNextPosition()
    {
        // Prepare input tensor
        List<float> inputFeatures = new List<float>();
        foreach (float[] state in historyBuffer)
        {
            inputFeatures.AddRange(state);
        }
        
        // Normalize input (would need to implement scaling logic)
        
        // Create input tensor
        var inputTensor = new DenseTensor<float>(inputFeatures.ToArray(), new[] { 1, inputFeatures.Count });
        var inputs = new List<NamedOnnxValue> { NamedOnnxValue.CreateFromTensor("input", inputTensor) };
        
        // Run inference
        IReadOnlyCollection<DisposableNamedOnnxValue> results = session.Run(inputs);
        
        // Process output
        var outputTensor = results.First().AsTensor<float>();
        
        // Denormalize output (would need to implement scaling logic)
        
        // Return predicted position
        return new Vector3(
            outputTensor[0],
            outputTensor[1],
            outputTensor[2]
        );
    }
}
"""
        else:  # LSTM or Transformer
            # These could be deployed using Barracuda (Unity ML) or TensorFlow.NET
            unity_code = """
using UnityEngine;
using System.Collections.Generic;
using Unity.Barracuda; // Requires Barracuda package from Package Manager

public class LaserTurretController : MonoBehaviour
{
    public GameObject laserDot;
    public GameObject tracker;
    
    public NNModel modelAsset; // Neural network model asset
    public TextAsset modelInfo; // JSON file with model parameters
    
    private Model runtimeModel;
    private IWorker worker;
    private int windowSize;
    private int predictionHorizon;
    private int featuresPerTimestep;
    private List<float[]> historyBuffer = new List<float[]>();
    
    void Start()
    {
        // Load model
        runtimeModel = ModelLoader.Load(modelAsset);
        worker = WorkerFactory.CreateWorker(WorkerFactory.Type.ComputePrecompiled, runtimeModel);
        
        // Parse model info JSON
        JSONObject info = new JSONObject(modelInfo.text);
        windowSize = (int)info["window_size"];
        predictionHorizon = (int)info["prediction_horizon"];
        featuresPerTimestep = (int)info["features_per_timestep"];
    }
    
    void OnDestroy()
    {
        worker?.Dispose();
    }
    
    void Update()
    {
        // Record current state
        Vector3 trackerPos = tracker.transform.position;
        Vector3 laserPos = laserDot.transform.position;
        
        // Calculate velocity and acceleration
        // (Implementation needed)
        Vector3 trackerVel = Vector3.zero; // Placeholder
        Vector3 trackerAcc = Vector3.zero; // Placeholder
        
        // Store in history buffer
        float[] currentState = new float[] {
            trackerPos.x, trackerPos.y, trackerPos.z,
            trackerVel.x, trackerVel.y, trackerVel.z,
            trackerAcc.x, trackerAcc.y, trackerAcc.z,
            laserPos.x, laserPos.y, laserPos.z
        };
        
        historyBuffer.Add(currentState);
        
        // Keep buffer at window size
        if (historyBuffer.Count > windowSize)
        {
            historyBuffer.RemoveAt(0);
        }
        
        // When we have enough history, predict next position
        if (historyBuffer.Count == windowSize)
        {
            Vector3 nextPosition = PredictNextPosition();
            
            // Move laser dot to predicted position
            // You might want to smooth this or implement a control strategy
            laserDot.transform.position = Vector3.Lerp(
                laserDot.transform.position, 
                nextPosition, 
                Time.deltaTime * 5f
            );
        }
    }
    
    Vector3 PredictNextPosition()
    {
        // Flatten history buffer into input tensor
        float[] inputFeatures = new float[windowSize * featuresPerTimestep];
        for (int i = 0; i < windowSize; i++)
        {
            float[] state = historyBuffer[i];
            for (int j = 0; j < featuresPerTimestep; j++)
            {
                inputFeatures[i * featuresPerTimestep + j] = state[j];
            }
        }
        
        // Normalize input (would need to implement scaling logic)
        
        // Create input tensor
        Tensor inputTensor;
        
        if (modelAsset.name.Contains("lstm") || modelAsset.name.Contains("transformer"))
        {
            // Reshape for sequence models [batch, sequence, features]
            inputTensor = new Tensor(1, windowSize, featuresPerTimestep, inputFeatures);
        }
        else
        {
            // Flatten for other models
            inputTensor = new Tensor(1, inputFeatures.Length, inputFeatures);
        }
        
        // Execute model
        worker.Execute(inputTensor);
        Tensor outputTensor = worker.PeekOutput();
        
        // Get output values (first prediction only)
        float x = outputTensor[0, 0];
        float y = outputTensor[0, 1];
        float z = outputTensor[0, 2];
        
        // Dispose tensor
        inputTensor.Dispose();
        
        // Denormalize output (would need to implement scaling logic)
        
        // Return predicted position
        return new Vector3(x, y, z);
    }
}
"""
        
        return unity_code
    
    def run_full_pipeline(self, data_path=None):
        """Run the complete ML pipeline"""
        if data_path is not None:
            self.data_path = data_path
        
        print("=== Running Complete ML Pipeline ===")
        
        # Load and explore data
        self.load_data()
        self.explore_data()
        
        # Preprocess data
        self.preprocess_data(window_size=10, prediction_horizon=5)
        
        # Train different models
        self.train_linear_model()
        self.train_xgboost_model()
        self.train_lstm_model()
        self.train_transformer_model()
        self.train_reinforcement_learning_model()
        
        # Compare models
        comparison = self.compare_models()
        
        # Get best model based on MSE
        best_model = comparison.iloc[0]['Model']
        print(f"\nBest performing model: {best_model}")
        
        # Prepare for deployment
        self.prepare_for_deployment(best_model)
        
        print("\n=== Pipeline Complete ===")
        print(f"Results and models saved to {self.output_dir}")
        
        return self.results


# Example usage
if __name__ == "__main__":
    # Specify path to CSV file from Unity recorder
    csv_path = "path/to/movement_log.csv"
    
    # Create and run pipeline
    pipeline = LaserTurretMLPipeline(csv_path)
    results = pipeline.run_full_pipeline()